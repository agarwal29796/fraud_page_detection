{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page-Based Features\n",
    "Page-Based Features are using information about pages which are calculated reputation ranking services. Some of these features give information about how much reliable a web site is. Some of Page-Based Features are given below.\n",
    "\n",
    "Global Pagerank\n",
    "Country Pagerank\n",
    "Position at the Alexa Top 1 Million Site\n",
    "Some Page-Based Features give us information about user activity on target site. Some of these features are given below. Obtaining these types of features is not easy. There are some paid services for obtaining these types of features.\n",
    "\n",
    "Estimated Number of Visits for the domain on a daily, weekly, or monthly basis\n",
    "Average Pageviews per visit\n",
    "Average Visit Duration\n",
    "Web traffic share per country\n",
    "Count of reference from Social Networks to the given domain\n",
    "Category of the domain\n",
    "Similar websites etc.\n",
    "\n",
    "## Web scraping javascript using python\n",
    "https://towardsdatascience.com/data-science-skills-web-scraping-javascript-using-python-97a29738353f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import re\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# links content and no. of links in webpage\n",
    "\n",
    "#connect to a URL\n",
    "# url=\"https://www.facebook.com\"\n",
    "# website = urllib2.urlopen(url)\n",
    "\n",
    "# #read html code\n",
    "# html = website.read()\n",
    "\n",
    "# #use re.findall to get all the links\n",
    "# links = re.findall('\"((http|ftp)s?://.*?)\"', html)\n",
    "\n",
    "# print links,len(links)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# match @ in url\n",
    "\n",
    "# def having_at_symbol(url):\n",
    "#     match = re.search('@', url)\n",
    "#     if match:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 1\n",
    "\n",
    "# url=\"https://www.facebook.com\"\n",
    "# print having_at_symbol(url)\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "## Alexa Rank\n",
    "\n",
    "# import sys, bs4\n",
    "# import urllib.request as urllib3\n",
    "# temp=input()\n",
    "# print (bs4.BeautifulSoup(urllib3.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\"+ temp).read(), \"xml\").find(\"REACH\")['RANK'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
